{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3853125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4e6b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(5)\n",
    "torch.save(x, \"x-file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a708e424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load(\"x-file\")\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992251a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros((4, 4))\n",
    "torch.save([x, y], \"x-files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93be8058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4]),\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2, y2 = torch.load('x-files')\n",
    "x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "034f17a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3, 4]),\n",
       " 'y': tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35ba59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.LazyLinear(256)\n",
    "        self.output = nn.LazyLinear(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd1d70b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[ 0.1876, -0.1921, -0.1587,  ...,  0.1955,  0.1670, -0.0005],\n",
       "                      [ 0.1346,  0.0992,  0.2123,  ...,  0.2234, -0.2018,  0.0415],\n",
       "                      [ 0.0576, -0.0227, -0.0413,  ...,  0.2058,  0.1628,  0.1089],\n",
       "                      ...,\n",
       "                      [-0.0316, -0.1540, -0.1011,  ...,  0.1275,  0.1285, -0.1605],\n",
       "                      [-0.0706, -0.1536,  0.1652,  ..., -0.1691,  0.1904,  0.0955],\n",
       "                      [-0.1444, -0.0972,  0.2119,  ..., -0.1653, -0.2035, -0.0326]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([ 0.1483, -0.1025,  0.1192, -0.1706, -0.2036, -0.1000,  0.0771, -0.1983,\n",
       "                      -0.1399, -0.1154,  0.1229,  0.2124,  0.0034, -0.0513,  0.1180, -0.2014,\n",
       "                      -0.0758, -0.2149, -0.1999,  0.1093,  0.1581,  0.0059, -0.1684,  0.0581,\n",
       "                       0.0692,  0.0646, -0.1540,  0.2097, -0.0269,  0.0713, -0.1526, -0.0052,\n",
       "                      -0.2119, -0.1467,  0.0525,  0.1668,  0.1483,  0.2211,  0.0450, -0.1488,\n",
       "                       0.0025, -0.0833,  0.0053, -0.0212, -0.1261, -0.1599,  0.0954, -0.2161,\n",
       "                       0.0997,  0.0715, -0.1692, -0.0155, -0.0758,  0.1657,  0.1882,  0.0815,\n",
       "                       0.0859, -0.1789, -0.0755,  0.1970,  0.2217,  0.0433,  0.1986, -0.2049,\n",
       "                      -0.2098, -0.0287, -0.0208, -0.1028,  0.0706,  0.1768, -0.1075, -0.0785,\n",
       "                       0.0970, -0.1540, -0.1741, -0.1063, -0.1347,  0.0892, -0.0900,  0.0153,\n",
       "                      -0.2071, -0.1465,  0.1419,  0.0662,  0.0486, -0.0438, -0.0820,  0.0629,\n",
       "                      -0.1495, -0.0142, -0.1577,  0.1064, -0.2014, -0.0354, -0.1701,  0.0590,\n",
       "                      -0.0858, -0.0578, -0.0228,  0.1087,  0.1743, -0.2054, -0.0507,  0.0539,\n",
       "                      -0.2217, -0.1749,  0.1896, -0.0793, -0.0927, -0.0526, -0.1896, -0.1118,\n",
       "                      -0.0322, -0.0230,  0.1141, -0.1129, -0.0368,  0.2131, -0.0275, -0.1844,\n",
       "                       0.1517, -0.2146, -0.0831, -0.1766, -0.1382, -0.0878, -0.1424, -0.0257,\n",
       "                       0.0620,  0.0291, -0.1611, -0.1395, -0.0550,  0.0872,  0.1278, -0.1278,\n",
       "                      -0.1549, -0.2067,  0.2171, -0.1089,  0.0016, -0.0177,  0.1595, -0.0664,\n",
       "                       0.1098,  0.0301,  0.1363,  0.1684, -0.0332,  0.1458, -0.0375, -0.0334,\n",
       "                      -0.1404,  0.0305, -0.1606, -0.0979, -0.0365,  0.1178, -0.1367,  0.0278,\n",
       "                      -0.2197,  0.1163,  0.0993, -0.1748,  0.0461,  0.1229, -0.1298,  0.1295,\n",
       "                       0.2203,  0.2116,  0.0110, -0.1321,  0.0469, -0.0546,  0.0724, -0.0816,\n",
       "                      -0.2222,  0.0672, -0.0706,  0.1320, -0.1193, -0.1480, -0.1887,  0.0986,\n",
       "                       0.2072, -0.2121,  0.0317,  0.2009,  0.2150,  0.0619,  0.0801,  0.1584,\n",
       "                      -0.0202,  0.0309,  0.0831,  0.1018, -0.1351, -0.0154,  0.1511, -0.1235,\n",
       "                      -0.1718,  0.1732,  0.1693,  0.0710,  0.0569,  0.1118,  0.1212, -0.1372,\n",
       "                       0.1266,  0.0759,  0.1233,  0.0953,  0.0597, -0.2005, -0.0893,  0.0283,\n",
       "                       0.0841, -0.0622, -0.1438, -0.0904,  0.0594,  0.0201,  0.1106, -0.0629,\n",
       "                      -0.0395,  0.1826,  0.0633, -0.0005,  0.0512, -0.2170, -0.2150, -0.1087,\n",
       "                       0.1185,  0.1732, -0.1782,  0.0255, -0.2091,  0.0546,  0.0894,  0.1474,\n",
       "                       0.0487, -0.0218,  0.0202,  0.1375,  0.0627,  0.1010, -0.1941,  0.0769,\n",
       "                      -0.0057,  0.1993,  0.0522, -0.1526, -0.1849,  0.1407,  0.0917,  0.0366])),\n",
       "             ('output.weight',\n",
       "              tensor([[-0.0601, -0.0054, -0.0204,  ..., -0.0433,  0.0122, -0.0119],\n",
       "                      [ 0.0492,  0.0140,  0.0262,  ..., -0.0080, -0.0342,  0.0433],\n",
       "                      [ 0.0107, -0.0007,  0.0375,  ...,  0.0502,  0.0220,  0.0548],\n",
       "                      ...,\n",
       "                      [-0.0530, -0.0277, -0.0189,  ...,  0.0250, -0.0304, -0.0146],\n",
       "                      [ 0.0185,  0.0400, -0.0496,  ..., -0.0411,  0.0111, -0.0544],\n",
       "                      [-0.0434,  0.0111, -0.0377,  ..., -0.0355, -0.0494, -0.0307]])),\n",
       "             ('output.bias',\n",
       "              tensor([-0.0536, -0.0090, -0.0573,  0.0026, -0.0319, -0.0191, -0.0060, -0.0304,\n",
       "                      -0.0043, -0.0452]))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c154f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"mlp.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7df9777f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "  (output): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84d3a394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
